{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent and Transient States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the long-term behaviour of markov chains, it helps to think about states in terms of **recurrent** and **transient**. \n",
    "\n",
    "Let $\\{X_n\\}$ be a markov chain. For state $i$, let $m_i$ be the return probability\n",
    "\n",
    "$$ m_i = \\mathbb{P}(X_n = i \\text{ for } n \\geq 1 | X_0 = i) $$\n",
    "\n",
    "If $m_i = 1$, the state $i$ is *recurrent*. If $m_i < 1$, state $i$ is *transient*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the point at state $i$, the expected number of visits to $i$ is\n",
    "\n",
    "$$ E[\\text{number of visits to }i | X_0 = i] = \\sum_{n=0}^\\infty \\mathbb{P}(X_n = i | X_0 = i) = \\sum_{n=1}^\\infty p_{ii}(n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a markov chain with transition matrix $P$. \n",
    "\n",
    "- If $i$ is recurrent, $E[\\text{number of visits to }i | X_0 = i]$ is infinite, and we return to state $i$ infinitely many times with probability 1.\n",
    "- If $i$ is transient, $E[\\text{number of visits to }i | X_0 = i]$ is finite, and we return to state $i$ infinitely many times with probability 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent and Transient Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a communicating class, every state is either recurrent or transient. Formally, let $i \\leftrightarrow{} j$---if $i$ is recurrent (or transient), $j$ is also recurrent (or transient).\n",
    "\n",
    "This way, we can refer to a communicating class as either a recurrent or a transient class. If the markov chain is irreducible, we can refer to it as a recurrent or transient markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every non-closed communicating class is transient.\n",
    "- Every finite closed communicating class is recurrent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive and Null Recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a class is labelled recurrent, i.e. $m_i = 1$ it may be useful to further classify it based on whether the expected return time $\\mu_i$ is finite or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\{X_n\\}$ be a markov chain with a recurrent state $i$, that is $m_i = 1$. If $\\mu_i < \\infty$, then state $i$ is **positive recurrent**. If $\\mu_i = \\infty$, then state $i$ is **null recurrent**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In a recurrent class, either all states are positive recurrent or null recurrent.\n",
    "- All finite closed classes are positive recurrent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. the simple symmetric random walk is recurrent with $\\mu_i = \\infty$, so it is null recurrent. It is known that random walks in $d$-dimensions are null recurrent if $d=1, 2$ but transient for higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strong Markov Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopping Time:** Let $\\{X_n\\} be a stochastic process in discrete time, and let $T$ be a random time. Then $T$ is a stopping time if for all $n$, whether or not $\\{T = n\\}$ occurs is completely determined by the variables $X_0, X_1, \\cdots, X_n$. \n",
    "\n",
    "To exemplify,\n",
    "\n",
    "1. \"The first visit to state i\" is a stopping time, since we know T when we reach i.\n",
    "\n",
    "2. \"The time-step before the first visit to i\" is not a stopping time, because we need to go further to tell if we were at T.\n",
    "\n",
    "Sometimes, what is true for a fixed time is also true for a random stopping time. If we use a markov property with a random stopping time, it is called the _strong markov property_.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally:\n",
    "\n",
    "Let $\\{X_n\\}$ be a markov chain on a state space $\\mathcal{S}$ and let $T$ be a stopping time that is finite with probability 1. Then\n",
    "\n",
    "$$ \\mathbb{P}(X_{T+1}=j | X_T=i, X_{T-1}=x_{T-1}, \\cdots, X_0=x_0) = p_{ij} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
